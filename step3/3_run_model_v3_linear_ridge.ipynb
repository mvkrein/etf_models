{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/mvkrein/etf_model/data'\n",
    "etf_data_file = os.path.join(data_path,'etf_new_var_20180910.csv')\n",
    "etf_data = pd.read_csv(etf_data_file,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_study_file = os.path.join(data_path,'ETF_list_min_6yr_history.csv')\n",
    "etf_list = pd.read_csv(etf_study_file,index_col=0)\n",
    "etf_data.sort_values(['Date','sym'],ascending=True,inplace=True)\n",
    "etf_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Date','sym','p', 'v', 'p_L05', 'v_L05', 'p_L10', 'v_L10', 'p_L21', 'v_L21', 'p_L42', 'v_L42', 'p_L63', \\\n",
    "                'v_L63', 'p_L84', 'v_L84', 'p_L126', 'v_L126', 'p_L189', 'v_L189', 'p_L252', 'v_L252',\\\n",
    "                'p_L-21', 'v_L-21', 'delta_p_L05', 'delta_p_L10', 'delta_p_L21', 'delta_p_L42', 'delta_p_L63', \\\n",
    "                'delta_p_L84', 'delta_p_L126', 'delta_p_L189', 'delta_p_L252', 'delta_p_L-21', 'delta_v_L05',\\\n",
    "                'delta_v_L10', 'delta_v_L21', 'delta_v_L42', 'delta_v_L63', 'delta_v_L84', 'delta_v_L126', \\\n",
    "                'delta_v_L189', 'delta_v_L252','rank_p_L-21', 'ivv_delta_p_L-21', 'target']\n",
    "\n",
    "rank_col = ['rank_p_L05','rank_p_L10','rank_p_L21','rank_p_L42',\\\n",
    "            'rank_p_L63','rank_p_L84','rank_p_L126','rank_p_L189','rank_p_L252']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(etf_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include_columns = [x for x in all_columns if x not in drop_columns]\n",
    "# include_columns = ['rank_p_L05','rank_p_L10','rank_p_L21','rank_p_L42',\\\n",
    "#             'rank_p_L63','rank_p_L84','rank_p_L126','rank_p_L189','rank_p_L252']\n",
    "# include_columns = ['rank_p_L05','rank_p_L21','rank_p_L42','rank_p_L252']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(1 % 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(include_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(etf_data['Date'].unique())\n",
    "# dates[1671]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = etf_list['Symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each year has 252 trading dates.  Need two years to fully develop variables.\n",
    "dt1 = 504 #This is the first day that all variables are developed\n",
    "# dt1 = 504 + 21 + 273 #This is the first day that all variables are developed 2016-04-07\n",
    "# make all dates relative to dt1\n",
    "# for one year training - add 252\n",
    "# to evaluate for one month outside the training window - add 273\n",
    "# to predict for the first day outside of the evaluation window (have to lag 21) - add 294\n",
    "dt_end = (len(dates) - 273 - 21) - 1\n",
    "# dt_end = dt1 + 1\n",
    "etf_predict_file = os.path.join(data_path,'etf_linear_ridge_20180928.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model to predict for  2015-02-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0704\n",
      "evaluation error: 0.0619\n",
      "R-squared score (training): 0.154\n",
      "R-squared score (test): 0.257\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0389\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "139    0.960784    0.767997    0.010741  0.060291\n",
      "67     0.882353    0.759569    0.010741  0.031835\n",
      "45     0.888889    0.687149    0.010741  0.036401\n",
      "70     0.986928    0.681460    0.010741  0.071770\n",
      "150    0.437908    0.675154    0.010741 -0.005800\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0282\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "39    0.287582    0.309723    0.010741 -0.016544\n",
      "15    0.764706    0.308307    0.010741  0.012313\n",
      "23    0.326797    0.302292    0.010741 -0.013518\n",
      "69    0.045752    0.301091    0.010741 -0.081433\n",
      "78    0.137255    0.288340    0.010741 -0.041616\n",
      "********************************************************\n",
      "Building model to predict for  2015-03-09\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0677\n",
      "evaluation error: 0.0856\n",
      "R-squared score (training): 0.186\n",
      "R-squared score (test): -0.027\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.091\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "6      0.915033    0.695831     0.00266  0.076116\n",
      "39     0.928105    0.685659     0.00266  0.082243\n",
      "0      0.908497    0.677425     0.00266  0.075889\n",
      "126    0.986928    0.675475     0.00266  0.178278\n",
      "53     0.738562    0.654879     0.00266  0.042591\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0339\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "138    0.777778    0.315670     0.00266  0.047020\n",
      "146    0.836601    0.302948     0.00266  0.054272\n",
      "62     0.019608    0.287100     0.00266 -0.024067\n",
      "133    0.816993    0.253881     0.00266  0.052917\n",
      "151    0.718954    0.248747     0.00266  0.039362\n",
      "********************************************************\n",
      "Building model to predict for  2015-04-08\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0652\n",
      "evaluation error: 0.109\n",
      "R-squared score (training): 0.216\n",
      "R-squared score (test): -0.308\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0021\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "38     0.235294    0.898598    0.004202 -0.018170\n",
      "46     0.960784    0.871139    0.004202  0.055012\n",
      "70     0.183007    0.862316    0.004202 -0.022443\n",
      "103    0.065359    0.807253    0.004202 -0.040441\n",
      "83     0.830065    0.798160    0.004202  0.015691\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0013\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "143    0.045752    0.173255    0.004202 -0.055974\n",
      "146    0.026144    0.167181    0.004202 -0.066340\n",
      "49     0.888889    0.137050    0.004202  0.022831\n",
      "54     0.980392    0.103668    0.004202  0.064196\n",
      "97     0.915033    0.052155    0.004202  0.028907\n",
      "********************************************************\n",
      "Building model to predict for  2015-05-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0653\n",
      "evaluation error: 0.0525\n",
      "R-squared score (training): 0.216\n",
      "R-squared score (test): 0.369\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0059\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "66     0.967320    0.928092   -0.001902  0.038891\n",
      "72     0.052288    0.897719   -0.001902 -0.069268\n",
      "130    0.888889    0.842357   -0.001902  0.018136\n",
      "88     0.960784    0.810008   -0.001902  0.035501\n",
      "83     0.810458    0.806946   -0.001902  0.006066\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0425\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "102    0.392157    0.200563   -0.001902 -0.012224\n",
      "80     0.235294    0.196245   -0.001902 -0.029327\n",
      "143    0.352941    0.195379   -0.001902 -0.016112\n",
      "57     0.032680    0.121186   -0.001902 -0.086982\n",
      "148    0.058824   -0.017566   -0.001902 -0.067742\n",
      "********************************************************\n",
      "Building model to predict for  2015-06-08\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0624\n",
      "evaluation error: 0.0829\n",
      "R-squared score (training): 0.250\n",
      "R-squared score (test): 0.005\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0763\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "15     0.006536    0.907795    -0.01377 -0.367158\n",
      "25     0.660131    0.757630    -0.01377 -0.011492\n",
      "146    0.973856    0.677648    -0.01377  0.026259\n",
      "57     0.535948    0.669230    -0.01377 -0.018068\n",
      "2      0.666667    0.660850    -0.01377 -0.011235\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.061\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "41     0.307190    0.295465    -0.01377 -0.043789\n",
      "62     0.209150    0.294941    -0.01377 -0.054275\n",
      "139    0.098039    0.283860    -0.01377 -0.079822\n",
      "37     0.137255    0.275487    -0.01377 -0.063771\n",
      "46     0.143791    0.170379    -0.01377 -0.063370\n",
      "********************************************************\n",
      "Building model to predict for  2015-07-08\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0603\n",
      "evaluation error: 0.073\n",
      "R-squared score (training): 0.276\n",
      "R-squared score (test): 0.124\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0757\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "15    1.000000    0.930756    0.018605  0.187063\n",
      "43    0.790850    0.817968    0.018605  0.038189\n",
      "37    0.764706    0.800107    0.018605  0.033998\n",
      "45    0.967320    0.767876    0.018605  0.081400\n",
      "68    0.777778    0.735703    0.018605  0.037741\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0156\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "126    0.803922    0.226941    0.018605  0.041403\n",
      "0      0.359477    0.198584    0.018605  0.000860\n",
      "6      0.313725    0.186744    0.018605 -0.001301\n",
      "60     0.732026    0.181071    0.018605  0.029782\n",
      "11     0.457516    0.170604    0.018605  0.007485\n",
      "********************************************************\n",
      "Building model to predict for  2015-08-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.059\n",
      "evaluation error: 0.0768\n",
      "R-squared score (training): 0.291\n",
      "R-squared score (test): 0.078\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0528\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "104    0.947712    0.986643   -0.076446  0.005111\n",
      "139    0.725490    0.903776   -0.076446 -0.053717\n",
      "103    0.712418    0.890206   -0.076446 -0.054852\n",
      "68     0.261438    0.884829   -0.076446 -0.099677\n",
      "95     0.686275    0.804736   -0.076446 -0.060969\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.1163\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "18    0.228758    0.028230   -0.076446 -0.105676\n",
      "97    0.137255   -0.036613   -0.076446 -0.117469\n",
      "54    0.045752   -0.041196   -0.076446 -0.151047\n",
      "32    0.673203   -0.068586   -0.076446 -0.063880\n",
      "11    0.071895   -0.180949   -0.076446 -0.143239\n",
      "********************************************************\n",
      "Building model to predict for  2015-09-04\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0581\n",
      "evaluation error: 0.0837\n",
      "R-squared score (training): 0.302\n",
      "R-squared score (test): -0.005\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0902\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "71     0.960784    0.834131    0.032631  0.093914\n",
      "151    0.875817    0.830984    0.032631  0.070399\n",
      "57     0.941176    0.825907    0.032631  0.089282\n",
      "133    0.967320    0.818311    0.032631  0.095076\n",
      "99     0.986928    0.790051    0.032631  0.102190\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0009\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "101    0.026144    0.275364    0.032631 -0.041594\n",
      "62     0.385621    0.264540    0.032631  0.018900\n",
      "84     0.503268    0.252529    0.032631  0.027751\n",
      "102    0.176471    0.238196    0.032631  0.004776\n",
      "66     0.071895    0.217050    0.032631 -0.014258\n",
      "********************************************************\n",
      "Building model to predict for  2015-10-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0596\n",
      "evaluation error: 0.101\n",
      "R-squared score (training): 0.284\n",
      "R-squared score (test): -0.214\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0475\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "79     0.111111    0.810940    0.063911 -0.008892\n",
      "120    0.875817    0.723179    0.063911  0.065964\n",
      "90     0.986928    0.718420    0.063911  0.089200\n",
      "150    0.660131    0.704440    0.063911  0.044555\n",
      "121    0.673203    0.693860    0.063911  0.046727\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0585\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "15     0.849673    0.203922    0.063911  0.062717\n",
      "16     0.568627    0.195897    0.063911  0.035642\n",
      "53     0.954248    0.192963    0.063911  0.085182\n",
      "126    0.771242    0.122025    0.063911  0.054756\n",
      "60     0.758170    0.120572    0.063911  0.054163\n",
      "********************************************************\n",
      "Building model to predict for  2015-11-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0605\n",
      "evaluation error: 0.0908\n",
      "R-squared score (training): 0.273\n",
      "R-squared score (test): -0.090\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0303\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "143    0.091503    0.858060   -0.003687 -0.057326\n",
      "50     0.084967    0.812744   -0.003687 -0.057692\n",
      "89     0.444444    0.689992   -0.003687 -0.006480\n",
      "26     0.398693    0.672481   -0.003687 -0.008807\n",
      "132    0.235294    0.671416   -0.003687 -0.020979\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0379\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "51     0.169935    0.254008   -0.003687 -0.036261\n",
      "78     0.065359    0.252975   -0.003687 -0.073245\n",
      "60     0.137255    0.177085   -0.003687 -0.044990\n",
      "126    0.189542    0.168075   -0.003687 -0.033092\n",
      "15     0.653595    0.145281   -0.003687 -0.001742\n",
      "********************************************************\n",
      "Building model to predict for  2015-12-04\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0606\n",
      "evaluation error: 0.152\n",
      "R-squared score (training): 0.271\n",
      "R-squared score (test): -0.819\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0538\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "11    0.222222    0.994444   -0.046016 -0.074912\n",
      "57    0.045752    0.975932   -0.046016 -0.111326\n",
      "72    0.771242    0.843907   -0.046016 -0.011894\n",
      "49    0.320261    0.829627   -0.046016 -0.066970\n",
      "23    0.797386    0.827252   -0.046016 -0.003755\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0109\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "24     0.699346    0.193232   -0.046016 -0.023972\n",
      "137    0.843137    0.193072   -0.046016 -0.000201\n",
      "59     0.856209    0.192031   -0.046016 -0.000060\n",
      "69     0.928105    0.102151   -0.046016  0.006667\n",
      "138    0.620915    0.087566   -0.046016 -0.036770\n",
      "********************************************************\n",
      "Building model to predict for  2016-01-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0614\n",
      "evaluation error: 0.103\n",
      "R-squared score (training): 0.262\n",
      "R-squared score (test): -0.236\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0841\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "84     0.039216    0.764500   -0.054663 -0.121793\n",
      "57     0.836601    0.719288   -0.054663  0.009464\n",
      "79     0.562092    0.713075   -0.054663 -0.038736\n",
      "15     0.013072    0.709224   -0.054663 -0.157275\n",
      "117    0.071895    0.703940   -0.054663 -0.112000\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0205\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "99     0.470588    0.323435   -0.054663 -0.049168\n",
      "98     0.888889    0.314744   -0.054663  0.016264\n",
      "146    0.960784    0.295564   -0.054663  0.051996\n",
      "89     0.111111    0.258834   -0.054663 -0.097678\n",
      "27     0.633987    0.243552   -0.054663 -0.024027\n",
      "********************************************************\n",
      "Building model to predict for  2016-02-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0607\n",
      "evaluation error: 0.111\n",
      "R-squared score (training): 0.270\n",
      "R-squared score (test): -0.333\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0437\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "83     0.803922    0.773753    0.055758  0.077209\n",
      "150    0.509804    0.765137    0.055758  0.049184\n",
      "73     0.052288    0.737706    0.055758 -0.000586\n",
      "87     0.921569    0.730956    0.055758  0.096087\n",
      "74     0.026144    0.729762    0.055758 -0.003247\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0365\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "38     0.281046    0.210050    0.055758  0.027119\n",
      "148    0.627451    0.206164    0.055758  0.058258\n",
      "25     0.176471    0.182129    0.055758  0.014553\n",
      "29     0.529412    0.158056    0.055758  0.050488\n",
      "23     0.346405    0.061302    0.055758  0.032186\n",
      "********************************************************\n",
      "Building model to predict for  2016-03-08\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0634\n",
      "evaluation error: 0.0987\n",
      "R-squared score (training): 0.238\n",
      "R-squared score (test): -0.184\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0008\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "117    0.111111    1.023915    0.033627 -0.005695\n",
      "66     0.058824    0.986776    0.033627 -0.021911\n",
      "67     0.333333    0.860825    0.033627  0.014635\n",
      "68     0.045752    0.839579    0.033627 -0.024218\n",
      "129    0.673203    0.815863    0.033627  0.033009\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0101\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "23     0.209150    0.143710    0.033627  0.005630\n",
      "85     0.771242    0.106971    0.033627  0.036725\n",
      "102    0.686275    0.054716    0.033627  0.033325\n",
      "138    0.098039    0.046106    0.033627 -0.009576\n",
      "69     0.084967    0.035828    0.033627 -0.015612\n",
      "********************************************************\n",
      "Building model to predict for  2016-04-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0619\n",
      "evaluation error: 0.109\n",
      "R-squared score (training): 0.256\n",
      "R-squared score (test): -0.305\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0113\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "70     0.006536    1.152403    0.008977 -0.090559\n",
      "88     0.013072    0.985370    0.008977 -0.079832\n",
      "117    0.921569    0.823122    0.008977  0.061634\n",
      "55     0.986928    0.799368    0.008977  0.125000\n",
      "66     0.830065    0.796935    0.008977  0.040135\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0002\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "17    0.202614    0.213516    0.008977 -0.001238\n",
      "0     0.124183    0.191602    0.008977 -0.010818\n",
      "6     0.176471    0.158403    0.008977 -0.005029\n",
      "50    0.045752    0.128859    0.008977 -0.038139\n",
      "32    0.901961    0.110946    0.008977  0.056305\n",
      "********************************************************\n",
      "Building model to predict for  2016-05-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.063\n",
      "evaluation error: 0.133\n",
      "R-squared score (training): 0.244\n",
      "R-squared score (test): -0.599\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0643\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "70     0.960784    1.039575    0.028819  0.091978\n",
      "88     0.986928    0.962584    0.028819  0.114706\n",
      "99     0.928105    0.785013    0.028819  0.075592\n",
      "127    0.150327    0.780712    0.028819  0.002900\n",
      "89     0.601307    0.770847    0.028819  0.036516\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0421\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "53     0.758170    0.245332    0.028819  0.043194\n",
      "27     0.581699    0.243406    0.028819  0.036133\n",
      "126    0.856209    0.231485    0.028819  0.057825\n",
      "11     0.679739    0.223155    0.028819  0.039563\n",
      "32     0.535948   -0.086699    0.028819  0.033784\n",
      "********************************************************\n",
      "Building model to predict for  2016-06-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0637\n",
      "evaluation error: 0.055\n",
      "R-squared score (training): 0.236\n",
      "R-squared score (test): 0.340\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0663\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "146    0.980392    1.051304   -0.005191  0.077340\n",
      "145    0.941176    0.859230   -0.005191  0.040056\n",
      "69     0.993464    0.831874   -0.005191  0.093411\n",
      "71     0.954248    0.824000   -0.005191  0.058194\n",
      "133    0.973856    0.795779   -0.005191  0.062289\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0458\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "39    0.352941    0.199677   -0.005191 -0.024085\n",
      "11    0.542484    0.168118   -0.005191 -0.008762\n",
      "78    0.143791    0.131022   -0.005191 -0.077806\n",
      "75    0.156863    0.098561   -0.005191 -0.075920\n",
      "32    0.215686   -0.082304   -0.005191 -0.042341\n",
      "********************************************************\n",
      "Building model to predict for  2016-07-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0655\n",
      "evaluation error: 0.0785\n",
      "R-squared score (training): 0.213\n",
      "R-squared score (test): 0.048\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.1254\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "54     0.986928    0.898055    0.041489  0.175680\n",
      "55     0.993464    0.869985    0.041489  0.225937\n",
      "32     0.529412    0.843743    0.041489  0.048595\n",
      "97     0.960784    0.804301    0.041489  0.119874\n",
      "103    0.653595    0.682390    0.041489  0.057030\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0456\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "27     0.444444    0.334938    0.041489  0.044108\n",
      "50     0.928105    0.302850    0.041489  0.107759\n",
      "65     0.261438    0.292542    0.041489  0.017231\n",
      "99     0.666667    0.278782    0.041489  0.059052\n",
      "138    0.176471    0.187756    0.041489  0.000000\n",
      "********************************************************\n",
      "Building model to predict for  2016-08-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0639\n",
      "evaluation error: 0.0873\n",
      "R-squared score (training): 0.233\n",
      "R-squared score (test): -0.048\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0398\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "76    0.895425    0.825774    0.004421  0.051487\n",
      "24    0.967320    0.774607    0.004421  0.071390\n",
      "46    0.980392    0.774162    0.004421  0.084112\n",
      "79    0.686275    0.770470    0.004421  0.025326\n",
      "89    0.019608    0.764737    0.004421 -0.033391\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0217\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "75    0.901961    0.295771    0.004421  0.051905\n",
      "23    0.032680    0.293607    0.004421 -0.014706\n",
      "52    0.745098    0.290576    0.004421  0.032764\n",
      "18    0.653595    0.265905    0.004421  0.021873\n",
      "50    0.562092    0.227823    0.004421  0.016861\n",
      "********************************************************\n",
      "Building model to predict for  2016-09-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0617\n",
      "evaluation error: 0.106\n",
      "R-squared score (training): 0.259\n",
      "R-squared score (test): -0.271\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0146\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "62     0.993464    0.806261   -0.010794  0.059566\n",
      "75     0.986928    0.805615   -0.010794  0.037321\n",
      "81     0.738562    0.796943   -0.010794 -0.001150\n",
      "149    0.457516    0.774521   -0.010794 -0.009555\n",
      "124    0.326797    0.766601   -0.010794 -0.013338\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0134\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "50     0.836601    0.266942   -0.010794  0.003189\n",
      "49     0.222222    0.265834   -0.010794 -0.020721\n",
      "84     0.973856    0.234687   -0.010794  0.033695\n",
      "139    0.980392    0.231295   -0.010794  0.035039\n",
      "83     0.921569    0.223544   -0.010794  0.015655\n",
      "********************************************************\n",
      "Building model to predict for  2016-10-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0601\n",
      "evaluation error: 0.118\n",
      "R-squared score (training): 0.278\n",
      "R-squared score (test): -0.419\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.081\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "88    0.013072    0.909586   -0.031675 -0.147890\n",
      "70    0.006536    0.839689   -0.031675 -0.151066\n",
      "44    0.568627    0.793582   -0.031675 -0.027161\n",
      "57    0.640523    0.771449   -0.031675 -0.022890\n",
      "25    0.156863    0.735382   -0.031675 -0.055869\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0093\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "53     0.176471    0.231287   -0.031675 -0.054110\n",
      "139    0.516340    0.204944   -0.031675 -0.029354\n",
      "55     0.816993    0.193062   -0.031675 -0.003311\n",
      "97     0.973856    0.060739   -0.031675  0.023529\n",
      "54     0.967320    0.025468   -0.031675  0.016896\n",
      "********************************************************\n",
      "Building model to predict for  2016-11-03\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0623\n",
      "evaluation error: 0.0719\n",
      "R-squared score (training): 0.252\n",
      "R-squared score (test): 0.137\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0223\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "72    0.156863    0.932978    0.057947 -0.044100\n",
      "25    0.692810    0.887053    0.057947  0.042553\n",
      "88    0.816993    0.850162    0.057947  0.073719\n",
      "44    0.071895    0.821904    0.057947 -0.062183\n",
      "70    0.875817    0.810775    0.057947  0.101511\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0709\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "73    0.150327    0.282096    0.057947 -0.044304\n",
      "55    0.013072    0.246894    0.057947 -0.122093\n",
      "69    0.026144    0.224977    0.057947 -0.102789\n",
      "31    0.549020    0.196751    0.057947  0.010188\n",
      "54    0.032680    0.176022    0.057947 -0.095466\n",
      "********************************************************\n",
      "Building model to predict for  2016-12-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0629\n",
      "evaluation error: 0.0978\n",
      "R-squared score (training): 0.245\n",
      "R-squared score (test): -0.173\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0376\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "70     0.392157    0.852820    0.030848  0.023041\n",
      "25     0.405229    0.837285    0.030848  0.024013\n",
      "117    0.673203    0.811895    0.030848  0.035125\n",
      "76     0.908497    0.801879    0.030848  0.058481\n",
      "24     0.836601    0.776304    0.030848  0.047545\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.025\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "28    0.947712    0.206349    0.030848  0.070645\n",
      "92    0.366013    0.189149    0.030848  0.022477\n",
      "14    0.039216    0.188707    0.030848 -0.011878\n",
      "23    0.490196    0.186789    0.030848  0.029299\n",
      "81    0.228758    0.181966    0.030848  0.014274\n",
      "********************************************************\n",
      "Building model to predict for  2017-01-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0639\n",
      "evaluation error: 0.11\n",
      "R-squared score (training): 0.233\n",
      "R-squared score (test): -0.321\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0533\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "52     0.869281    0.850583    0.011592  0.044900\n",
      "29     0.986928    0.799665    0.011592  0.083953\n",
      "118    0.725490    0.781756    0.011592  0.020066\n",
      "67     0.424837    0.753342    0.011592  0.006066\n",
      "148    0.993464    0.744447    0.011592  0.111395\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0562\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "23    0.366013    0.206167    0.011592  0.003626\n",
      "14    0.934641    0.205000    0.011592  0.056055\n",
      "55    1.000000    0.167588    0.011592  0.126593\n",
      "54    0.915033    0.165174    0.011592  0.051391\n",
      "31    0.849673    0.063347    0.011592  0.043210\n",
      "********************************************************\n",
      "Building model to predict for  2017-02-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0658\n",
      "evaluation error: 0.0992\n",
      "R-squared score (training): 0.210\n",
      "R-squared score (test): -0.191\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0111\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "118    0.437908    0.715123    0.033467  0.005835\n",
      "39     0.862745    0.693868    0.033467  0.032412\n",
      "124    0.189542    0.693754    0.033467 -0.006423\n",
      "144    0.143791    0.684365    0.033467 -0.009289\n",
      "78     0.013072    0.682377    0.033467 -0.078063\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0231\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "23     0.104575    0.286111    0.033467 -0.017262\n",
      "31     0.019608    0.279397    0.033467 -0.077487\n",
      "143    0.052288    0.254982    0.033467 -0.030343\n",
      "55     0.764706    0.225073    0.033467  0.027904\n",
      "101    0.091503    0.151848    0.033467 -0.018127\n",
      "********************************************************\n",
      "Building model to predict for  2017-03-08\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0674\n",
      "evaluation error: 0.113\n",
      "R-squared score (training): 0.190\n",
      "R-squared score (test): -0.358\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.007\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "112    0.326797    0.849032   -0.000638  0.005918\n",
      "118    0.045752    0.803128   -0.000638 -0.014789\n",
      "114    0.215686    0.752798   -0.000638  0.000518\n",
      "29     0.908497    0.751670   -0.000638  0.047098\n",
      "96     0.124183    0.733527   -0.000638 -0.003688\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0335\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "49     0.627451    0.326197   -0.000638  0.023885\n",
      "50     0.823529    0.316754   -0.000638  0.038545\n",
      "148    0.496732    0.307238   -0.000638  0.015234\n",
      "143    0.882353    0.253465   -0.000638  0.044106\n",
      "28     0.888889    0.226533   -0.000638  0.045535\n",
      "********************************************************\n",
      "Building model to predict for  2017-04-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0692\n",
      "evaluation error: 0.0807\n",
      "R-squared score (training): 0.169\n",
      "R-squared score (test): 0.031\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0704\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "33    0.980392    0.902903    0.018024  0.092040\n",
      "40    0.967320    0.740501    0.018024  0.088374\n",
      "22    0.836601    0.727519    0.018024  0.050742\n",
      "24    0.947712    0.718312    0.018024  0.084792\n",
      "41    0.758170    0.685210    0.018024  0.035910\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0027\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "62    0.026144    0.241760    0.018024 -0.062166\n",
      "11    0.215686    0.241371    0.018024  0.000549\n",
      "28    0.862745    0.234885    0.018024  0.052602\n",
      "27    0.411765    0.223825    0.018024  0.009577\n",
      "97    0.111111    0.156972    0.018024 -0.013937\n",
      "********************************************************\n",
      "Building model to predict for  2017-05-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0693\n",
      "evaluation error: 0.0952\n",
      "R-squared score (training): 0.168\n",
      "R-squared score (test): -0.142\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0157\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "40     0.307190    0.792034    0.016918  0.010826\n",
      "52     0.928105    0.768947    0.016918  0.047050\n",
      "33     0.209150    0.669450    0.016918  0.004556\n",
      "62     0.065359    0.668473    0.016918 -0.012830\n",
      "118    0.732026    0.663024    0.016918  0.028816\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0049\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "81     0.039216    0.290661    0.016918 -0.040798\n",
      "138    0.986928    0.285525    0.016918  0.080467\n",
      "103    0.411765    0.284236    0.016918  0.014653\n",
      "75     0.013072    0.248996    0.016918 -0.074023\n",
      "79     0.901961    0.231756    0.016918  0.044360\n",
      "********************************************************\n",
      "Building model to predict for  2017-06-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0683\n",
      "evaluation error: 0.107\n",
      "R-squared score (training): 0.180\n",
      "R-squared score (test): -0.284\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0019\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "72    0.777778    0.759784   -0.001747  0.008710\n",
      "52    0.901961    0.723901   -0.001747  0.024692\n",
      "77    0.300654    0.716895   -0.001747 -0.009700\n",
      "45    0.281046    0.701323   -0.001747 -0.010426\n",
      "49    0.529412    0.696114   -0.001747 -0.003965\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0003\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "96     0.758170    0.227432   -0.001747  0.007227\n",
      "112    0.928105    0.221029   -0.001747  0.033861\n",
      "78     0.032680    0.217275   -0.001747 -0.046993\n",
      "55     0.843137    0.215020   -0.001747  0.014671\n",
      "75     0.379085    0.202647   -0.001747 -0.007408\n",
      "********************************************************\n",
      "Building model to predict for  2017-07-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.069\n",
      "evaluation error: 0.0711\n",
      "R-squared score (training): 0.172\n",
      "R-squared score (test): 0.147\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0485\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "138    0.699346    0.868479     0.02384  0.040733\n",
      "52     0.718954    0.840421     0.02384  0.041559\n",
      "80     0.790850    0.737504     0.02384  0.049929\n",
      "79     0.856209    0.735965     0.02384  0.056917\n",
      "152    0.830065    0.728344     0.02384  0.053209\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0144\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "103    0.803922    0.310808     0.02384  0.050614\n",
      "68     0.071895    0.308315     0.02384 -0.000867\n",
      "81     0.575163    0.283716     0.02384  0.028893\n",
      "117    0.281046    0.280400     0.02384  0.012356\n",
      "112    0.032680    0.221358     0.02384 -0.018804\n",
      "********************************************************\n",
      "Building model to predict for  2017-08-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.069\n",
      "evaluation error: 0.0937\n",
      "R-squared score (training): 0.172\n",
      "R-squared score (test): -0.125\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0075\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "89     0.771242    0.882972   -0.003647  0.010811\n",
      "36     0.823529    0.709718   -0.003647  0.016943\n",
      "112    0.522876    0.698932   -0.003647  0.001951\n",
      "139    0.738562    0.695393   -0.003647  0.008196\n",
      "65     0.431373    0.693443   -0.003647 -0.000347\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0464\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "14    0.934641    0.286304   -0.003647  0.044643\n",
      "40    0.732026    0.283300   -0.003647  0.007908\n",
      "78    0.202614    0.256751   -0.003647 -0.008901\n",
      "55    1.000000    0.228518   -0.003647  0.132673\n",
      "97    0.960784    0.214746   -0.003647  0.055622\n",
      "********************************************************\n",
      "Building model to predict for  2017-09-06\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0695\n",
      "evaluation error: 0.138\n",
      "R-squared score (training): 0.166\n",
      "R-squared score (test): -0.660\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0066\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "52     0.032680    1.001754    0.036537 -0.038804\n",
      "138    0.013072    0.803272    0.036537 -0.069947\n",
      "0      0.633987    0.796647    0.036537  0.030797\n",
      "126    0.908497    0.775423    0.036537  0.067208\n",
      "6      0.803922    0.760392    0.036537  0.043931\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0803\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "122    0.901961    0.181417    0.036537  0.066300\n",
      "94     0.954248    0.167112    0.036537  0.092923\n",
      "95     0.967320    0.155575    0.036537  0.101030\n",
      "55     0.542484    0.149366    0.036537  0.026224\n",
      "78     1.000000    0.076115    0.036537  0.115174\n",
      "********************************************************\n",
      "Building model to predict for  2017-10-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0709\n",
      "evaluation error: 0.0875\n",
      "R-squared score (training): 0.148\n",
      "R-squared score (test): -0.049\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0209\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "138    0.725490    0.779691    0.014822  0.014659\n",
      "52     0.019608    0.773095    0.014822 -0.071667\n",
      "126    0.359477    0.743136    0.014822  0.001369\n",
      "148    0.091503    0.727412    0.014822 -0.018113\n",
      "25     0.058824    0.726753    0.014822 -0.030577\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0067\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "66    0.189542    0.311921    0.014822 -0.009052\n",
      "81    0.215686    0.286346    0.014822 -0.004736\n",
      "33    0.163399    0.269839    0.014822 -0.013769\n",
      "75    0.934641    0.268457    0.014822  0.037583\n",
      "78    0.052288    0.225385    0.014822 -0.043677\n",
      "********************************************************\n",
      "Building model to predict for  2017-11-03\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0704\n",
      "evaluation error: 0.101\n",
      "R-squared score (training): 0.155\n",
      "R-squared score (test): -0.217\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0007\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "126    0.117647    0.849326    0.018487 -0.016406\n",
      "148    0.058824    0.836426    0.018487 -0.035922\n",
      "52     0.555556    0.835398    0.018487  0.004588\n",
      "25     0.941176    0.801820    0.018487  0.034239\n",
      "55     0.653595    0.777802    0.018487  0.010224\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0251\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "41     0.405229    0.330618    0.018487 -0.000507\n",
      "95     0.934641    0.306159    0.018487  0.034235\n",
      "104    1.000000    0.293483    0.018487  0.089537\n",
      "81     0.601307    0.289269    0.018487  0.006246\n",
      "62     0.274510    0.254189    0.018487 -0.003819\n",
      "********************************************************\n",
      "Building model to predict for  2017-12-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0702\n",
      "evaluation error: 0.0675\n",
      "R-squared score (training): 0.157\n",
      "R-squared score (test): 0.190\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0883\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "37     0.392157    0.791900    0.043916  0.036315\n",
      "46     0.954248    0.783061    0.043916  0.101562\n",
      "31     0.915033    0.775260    0.043916  0.091641\n",
      "148    0.986928    0.762908    0.043916  0.133615\n",
      "139    0.843137    0.754174    0.043916  0.078567\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0382\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "114    0.326797    0.268328    0.043916  0.029461\n",
      "94     0.267974    0.264730    0.043916  0.024607\n",
      "32     0.888889    0.231014    0.043916  0.086025\n",
      "95     0.248366    0.206201    0.043916  0.021928\n",
      "112    0.313725    0.190835    0.043916  0.028979\n",
      "********************************************************\n",
      "Building model to predict for  2018-01-05\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0695\n",
      "evaluation error: 0.101\n",
      "R-squared score (training): 0.166\n",
      "R-squared score (test): -0.207\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0185\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "52     0.941176    0.765509   -0.014782  0.020792\n",
      "132    0.032680    0.756840   -0.014782 -0.071847\n",
      "35     0.183007    0.751823   -0.014782 -0.031646\n",
      "90     0.862745    0.710318   -0.014782  0.007660\n",
      "39     0.477124    0.687544   -0.014782 -0.017348\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0467\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "77    0.424837    0.304784   -0.014782 -0.018305\n",
      "81    0.039216    0.296075   -0.014782 -0.069426\n",
      "28    0.065359    0.254147   -0.014782 -0.059233\n",
      "31    0.405229    0.216170   -0.014782 -0.018970\n",
      "78    0.052288    0.151751   -0.014782 -0.067536\n",
      "********************************************************\n",
      "Building model to predict for  2018-02-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0691\n",
      "evaluation error: 0.081\n",
      "R-squared score (training): 0.170\n",
      "R-squared score (test): -0.011\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0047\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "126    0.196078    0.720020    0.017953 -0.010701\n",
      "104    0.058824    0.682951    0.017953 -0.037759\n",
      "46     0.352941    0.675681    0.017953 -0.002727\n",
      "57     0.960784    0.673415    0.017953  0.066020\n",
      "39     0.627451    0.661502    0.017953  0.008631\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.008\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "136    0.470588    0.267431    0.017953  0.000944\n",
      "74     0.424837    0.265940    0.017953 -0.001136\n",
      "137    0.431373    0.258168    0.017953 -0.000884\n",
      "141    0.503268    0.254732    0.017953  0.001814\n",
      "68     0.901961    0.231979    0.017953  0.039387\n",
      "********************************************************\n",
      "Building model to predict for  2018-03-08\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0694\n",
      "evaluation error: 0.115\n",
      "R-squared score (training): 0.167\n",
      "R-squared score (test): -0.385\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0015\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "47     0.777778    0.799434   -0.044343  0.005199\n",
      "104    0.836601    0.788161   -0.044343  0.008038\n",
      "48     0.758170    0.769169   -0.044343  0.003772\n",
      "22     0.562092    0.755925   -0.044343 -0.005621\n",
      "58     0.607843    0.752648   -0.044343 -0.003862\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0161\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "74     0.764706    0.279616   -0.044343  0.004313\n",
      "133    0.993464    0.278926   -0.044343  0.028421\n",
      "144    0.862745    0.277971   -0.044343  0.008578\n",
      "72     1.000000    0.267169   -0.044343  0.029567\n",
      "73     0.875817    0.256769   -0.044343  0.009544\n",
      "********************************************************\n",
      "Building model to predict for  2018-04-09\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0712\n",
      "evaluation error: 0.0764\n",
      "R-squared score (training): 0.146\n",
      "R-squared score (test): 0.083\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0143\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "84     0.836601    0.704445    0.022764  0.031170\n",
      "103    0.366013    0.694932    0.022764 -0.001938\n",
      "25     0.699346    0.659614    0.022764  0.018200\n",
      "143    0.222222    0.653188    0.022764 -0.010277\n",
      "139    0.869281    0.650707    0.022764  0.034237\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0351\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "138    0.320261    0.353201    0.022764 -0.003213\n",
      "88     0.091503    0.350048    0.022764 -0.032006\n",
      "97     0.039216    0.343393    0.022764 -0.049959\n",
      "72     0.385621    0.323031    0.022764 -0.001026\n",
      "52     0.019608    0.313458    0.022764 -0.089272\n",
      "********************************************************\n",
      "Building model to predict for  2018-05-08\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0707\n",
      "evaluation error: 0.0897\n",
      "R-squared score (training): 0.151\n",
      "R-squared score (test): -0.076\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0072\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "148    0.065359    0.782723    0.039378 -0.035907\n",
      "53     0.509804    0.757803    0.039378  0.008998\n",
      "46     0.078431    0.729603    0.039378 -0.031086\n",
      "67     0.581699    0.720602    0.039378  0.018773\n",
      "11     0.320261    0.716713    0.039378  0.003334\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: 0.0082\n",
      "    true_value  pred_value  mkt_return   returns\n",
      "28    0.189542    0.280300    0.039378 -0.008449\n",
      "62    0.215686    0.247307    0.039378 -0.005666\n",
      "81    0.666667    0.177698    0.039378  0.026825\n",
      "78    0.372549    0.132314    0.039378  0.004237\n",
      "75    0.627451   -0.012072    0.039378  0.024161\n",
      "********************************************************\n",
      "Building model to predict for  2018-06-07\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.0688\n",
      "evaluation error: 0.122\n",
      "R-squared score (training): 0.174\n",
      "R-squared score (test): -0.466\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: -0.0195\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "143    0.026144    0.886763    0.006674 -0.092768\n",
      "14     0.111111    0.883962    0.006674 -0.046723\n",
      "46     0.209150    0.869186    0.006674 -0.025759\n",
      "49     0.006536    0.849747    0.006674 -0.096621\n",
      "52     1.000000    0.813043    0.006674  0.164132\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0082\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "25     0.771242    0.313918    0.006674  0.011274\n",
      "50     0.124183    0.302561    0.006674 -0.045705\n",
      "139    0.130719    0.288430    0.006674 -0.045480\n",
      "122    0.718954    0.285396    0.006674  0.009295\n",
      "112    0.915033    0.267510    0.006674  0.029686\n",
      "********************************************************\n",
      "Building model to predict for  2018-07-09\n",
      "Model Eval Results:\n",
      "*****************************\n",
      "training error: 0.069\n",
      "evaluation error: 0.0952\n",
      "R-squared score (training): 0.171\n",
      "R-squared score (test): -0.142\n",
      "*****************************\n",
      "Model Top 5 Picks\n",
      " Avg rtn top 5: 0.0092\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "55     0.986928    0.846213    0.027376  0.073643\n",
      "14     0.581699    0.803484    0.027376  0.007524\n",
      "148    0.006536    0.789811    0.027376 -0.129697\n",
      "143    0.960784    0.748420    0.027376  0.058922\n",
      "49     0.901961    0.748354    0.027376  0.035503\n",
      "Model Bottom 5 Picks\n",
      " Avg rtn bottom 5: -0.0156\n",
      "     true_value  pred_value  mkt_return   returns\n",
      "95     0.189542    0.281474    0.027376 -0.009717\n",
      "114    0.202614    0.278546    0.027376 -0.009391\n",
      "112    0.045752    0.256796    0.027376 -0.032514\n",
      "75     0.150327    0.222332    0.027376 -0.013146\n",
      "84     0.143791    0.172761    0.027376 -0.013180\n",
      "********************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(dt1,dt_end,21):\n",
    "    print(\"Building model to predict for \",dates[i+273])\n",
    "    x_train = etf_data.loc[((etf_data['Date']>=dates[i]) & (etf_data['Date']<dates[i+252])),include_columns] #train with 12 mos\n",
    "    y_train = etf_data.loc[((etf_data['Date']>=dates[i]) & (etf_data['Date']<dates[i+252])),['rank_p_L-21']] #train with 12 mos\n",
    "\n",
    "    x_test = etf_data.loc[(etf_data['Date']==dates[i+273]),include_columns]#predict one day-must be 21 days removed from training\n",
    "    y_test = etf_data.loc[(etf_data['Date']==dates[i+273]),['rank_p_L-21']] #predict if etf >= market\n",
    "    returns = etf_data.loc[(etf_data['Date']==dates[i+273]),['delta_p_L-21']]\n",
    "    mkt_return = etf_data.loc[(etf_data['Date']==dates[i+273]),['ivv_delta_p_L-21']]\n",
    "    x_train_nmpy = x_train.as_matrix()\n",
    "    y_train_nmpy = np.ravel(y_train.as_matrix())\n",
    "\n",
    "    x_test_nmpy = x_test.as_matrix()\n",
    "    y_test_nmpy = np.ravel(y_test.as_matrix())\n",
    "    returns_nmpy = returns.as_matrix()\n",
    "    mkt_return_nmpy = mkt_return.as_matrix()\n",
    "\n",
    "    lm = linear_model.Ridge (alpha = 0.8)\n",
    "#     lm = LinearRegression()\n",
    "\n",
    "    lm.fit(x_train_nmpy, y_train_nmpy)\n",
    "    \n",
    "    y_train_model = lm.predict(x_train_nmpy)\n",
    "    y_pred_model = lm.predict(x_test_nmpy)\n",
    "\n",
    "\n",
    "    y_check = np.column_stack((y_test_nmpy, y_pred_model,mkt_return_nmpy,returns_nmpy))\n",
    "    y_check_df = pd.DataFrame(y_check,columns=['true_value','pred_value','mkt_return','returns'])\n",
    "    y_check_df.sort_values('pred_value',inplace=True,ascending=False)\n",
    "    \n",
    "\n",
    "    train_error = mean_squared_error(y_train_nmpy,lm.predict(x_train_nmpy))\n",
    "    eval_error = mean_squared_error(y_test_nmpy,y_pred_model)\n",
    "\n",
    "    print('Model Eval Results:')\n",
    "    print('*****************************')\n",
    "\n",
    "    print(f'training error: {train_error:.3}')\n",
    "    print(f'evaluation error: {eval_error:.3}')\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(r2_score(y_train_nmpy,y_train_model)))\n",
    "    print('R-squared score (test): {:.3f}'\n",
    "     .format(r2_score(y_test_nmpy, y_pred_model)))\n",
    "\n",
    "    print('*****************************')\n",
    "    print(\"Model Top 5 Picks\")\n",
    "    print(\" Avg rtn top 5:\", round(y_check_df['returns'][0:5].mean(),4))\n",
    "    print(y_check_df.head(5))\n",
    "    print(\"Model Bottom 5 Picks\")\n",
    "    print(\" Avg rtn bottom 5:\", round(y_check_df['returns'][-5:].mean(),4))\n",
    "    print(y_check_df.tail(5))\n",
    "    print('********************************************************')\n",
    "    if i == dt1:\n",
    "        predict_data = etf_data.loc[(etf_data['Date']==dates[i+273]),['Date','sym','rank_p_L-21']]\n",
    "        predict_data['predict'] = y_pred_model\n",
    "        predict_data.to_csv(etf_predict_file)\n",
    "    else:\n",
    "        predict_data = etf_data.loc[(etf_data['Date']==dates[i+273]),['Date','sym','rank_p_L-21']]\n",
    "        predict_data['predict'] = y_pred_model\n",
    "        predict_data.to_csv(etf_predict_file,header=False,mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11638660086020819"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.854918</td>\n",
       "      <td>w252_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.854918</td>\n",
       "      <td>w252_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700064</td>\n",
       "      <td>w189_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700064</td>\n",
       "      <td>w189_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.576567</td>\n",
       "      <td>w126_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.576567</td>\n",
       "      <td>w126_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.558991</td>\n",
       "      <td>w189_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.558991</td>\n",
       "      <td>w189_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.529128</td>\n",
       "      <td>w189_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.529128</td>\n",
       "      <td>w189_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.516502</td>\n",
       "      <td>w252_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.516502</td>\n",
       "      <td>w252_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.510651</td>\n",
       "      <td>w126_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.510651</td>\n",
       "      <td>w126_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.443491</td>\n",
       "      <td>w189_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.443491</td>\n",
       "      <td>w189_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.413692</td>\n",
       "      <td>w126_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.413692</td>\n",
       "      <td>w126_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.398268</td>\n",
       "      <td>w63_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.398268</td>\n",
       "      <td>w63_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.374467</td>\n",
       "      <td>w252_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.374467</td>\n",
       "      <td>w252_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.359505</td>\n",
       "      <td>w63_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.359505</td>\n",
       "      <td>w63_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.357035</td>\n",
       "      <td>w189_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.357035</td>\n",
       "      <td>w189_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.337470</td>\n",
       "      <td>w126_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.337470</td>\n",
       "      <td>w126_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.335343</td>\n",
       "      <td>w42_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.335343</td>\n",
       "      <td>w42_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.320384</td>\n",
       "      <td>w42_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.320384</td>\n",
       "      <td>w42_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.313885</td>\n",
       "      <td>w21_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.313885</td>\n",
       "      <td>w21_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.279962</td>\n",
       "      <td>w252_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.279962</td>\n",
       "      <td>w252_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.261484</td>\n",
       "      <td>w84_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.261484</td>\n",
       "      <td>w84_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>w84_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>w84_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.223865</td>\n",
       "      <td>w42_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.223865</td>\n",
       "      <td>w42_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.216226</td>\n",
       "      <td>w252_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.216226</td>\n",
       "      <td>w252_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.196041</td>\n",
       "      <td>w84_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.196041</td>\n",
       "      <td>w84_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.160810</td>\n",
       "      <td>w252_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.160810</td>\n",
       "      <td>w252_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.152409</td>\n",
       "      <td>w84_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.152409</td>\n",
       "      <td>w84_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.151127</td>\n",
       "      <td>w5_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.151127</td>\n",
       "      <td>w5_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.149539</td>\n",
       "      <td>w10_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.149539</td>\n",
       "      <td>w10_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.113896</td>\n",
       "      <td>w63_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.113896</td>\n",
       "      <td>w63_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.105488</td>\n",
       "      <td>w42_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.105488</td>\n",
       "      <td>w42_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.104074</td>\n",
       "      <td>w10_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.104074</td>\n",
       "      <td>w10_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.096456</td>\n",
       "      <td>w84_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.096456</td>\n",
       "      <td>w84_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.079802</td>\n",
       "      <td>w5_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.079802</td>\n",
       "      <td>w5_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.066376</td>\n",
       "      <td>w63_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.066376</td>\n",
       "      <td>w63_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.065465</td>\n",
       "      <td>w126_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.065465</td>\n",
       "      <td>w126_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.050855</td>\n",
       "      <td>w10_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.050855</td>\n",
       "      <td>w10_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.045238</td>\n",
       "      <td>w21_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.045238</td>\n",
       "      <td>w21_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.044993</td>\n",
       "      <td>rank_p_L252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.044993</td>\n",
       "      <td>rank_v_L252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.042655</td>\n",
       "      <td>rank_v_L126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.042655</td>\n",
       "      <td>rank_p_L126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.027228</td>\n",
       "      <td>w10_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.027228</td>\n",
       "      <td>w10_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.026194</td>\n",
       "      <td>w5_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.026194</td>\n",
       "      <td>w5_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.023905</td>\n",
       "      <td>w10_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.023905</td>\n",
       "      <td>w10_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.023413</td>\n",
       "      <td>w21_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.023413</td>\n",
       "      <td>w21_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.014465</td>\n",
       "      <td>rank_v_L189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.014465</td>\n",
       "      <td>rank_p_L189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.009666</td>\n",
       "      <td>w42_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.009666</td>\n",
       "      <td>w42_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.008423</td>\n",
       "      <td>w42_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.008423</td>\n",
       "      <td>w42_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.008272</td>\n",
       "      <td>rank_v_L42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.008272</td>\n",
       "      <td>rank_p_L42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.005937</td>\n",
       "      <td>ivv_w84_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.005937</td>\n",
       "      <td>ivv_w84_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.004918</td>\n",
       "      <td>ivv_w42_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.004918</td>\n",
       "      <td>ivv_w42_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.004844</td>\n",
       "      <td>rank_v_L05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.004844</td>\n",
       "      <td>rank_p_L05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.003401</td>\n",
       "      <td>ivv_w189_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.003401</td>\n",
       "      <td>ivv_w189_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.003149</td>\n",
       "      <td>ivv_w21_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.003149</td>\n",
       "      <td>ivv_w21_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.003045</td>\n",
       "      <td>ivv_w42_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.003045</td>\n",
       "      <td>ivv_w42_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.003014</td>\n",
       "      <td>ivv_w21_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.003014</td>\n",
       "      <td>ivv_w21_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.002506</td>\n",
       "      <td>ivv_w10_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.002506</td>\n",
       "      <td>ivv_w10_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.002441</td>\n",
       "      <td>ivv_w189_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.002441</td>\n",
       "      <td>ivv_w189_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.002134</td>\n",
       "      <td>w5_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.002134</td>\n",
       "      <td>w5_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.002066</td>\n",
       "      <td>ivv_w5_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.002066</td>\n",
       "      <td>ivv_w5_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.002059</td>\n",
       "      <td>ivv_w42_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.002059</td>\n",
       "      <td>ivv_w42_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.002009</td>\n",
       "      <td>ivv_w63_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.002009</td>\n",
       "      <td>ivv_w63_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.001821</td>\n",
       "      <td>ivv_w21_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.001821</td>\n",
       "      <td>ivv_w21_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.001819</td>\n",
       "      <td>ivv_w10_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.001819</td>\n",
       "      <td>ivv_w10_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>ivv_rank_p_L252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>ivv_rank_v_L252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>ivv_w63_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>ivv_w63_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.001705</td>\n",
       "      <td>ivv_w126_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.001705</td>\n",
       "      <td>ivv_w126_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>ivv_w252_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>ivv_w252_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.001624</td>\n",
       "      <td>ivv_w252_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.001624</td>\n",
       "      <td>ivv_w252_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.001456</td>\n",
       "      <td>ivv_w252_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.001456</td>\n",
       "      <td>ivv_w252_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.001414</td>\n",
       "      <td>ivv_w63_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.001414</td>\n",
       "      <td>ivv_w63_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.001334</td>\n",
       "      <td>ivv_w42_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.001334</td>\n",
       "      <td>ivv_w42_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.001208</td>\n",
       "      <td>ivv_w84_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.001208</td>\n",
       "      <td>ivv_w84_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.001153</td>\n",
       "      <td>ivv_w21_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.001153</td>\n",
       "      <td>ivv_w21_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.001037</td>\n",
       "      <td>ivv_w189_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.001037</td>\n",
       "      <td>ivv_w189_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.000996</td>\n",
       "      <td>ivv_w10_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.000996</td>\n",
       "      <td>ivv_w10_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.000979</td>\n",
       "      <td>ivv_w5_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.000979</td>\n",
       "      <td>ivv_w5_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.000696</td>\n",
       "      <td>ivv_rank_v_L189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.000696</td>\n",
       "      <td>ivv_rank_p_L189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>ivv_rank_v_L84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>ivv_rank_p_L84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.000620</td>\n",
       "      <td>ivv_w42_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.000620</td>\n",
       "      <td>ivv_w42_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.000586</td>\n",
       "      <td>ivv_w5_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.000586</td>\n",
       "      <td>ivv_w5_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.000532</td>\n",
       "      <td>ivv_w252_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.000532</td>\n",
       "      <td>ivv_w252_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.000529</td>\n",
       "      <td>ivv_w10_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000529</td>\n",
       "      <td>ivv_w10_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.000476</td>\n",
       "      <td>ivv_w252_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.000476</td>\n",
       "      <td>ivv_w252_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.000429</td>\n",
       "      <td>ivv_rank_v_L10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.000429</td>\n",
       "      <td>ivv_rank_p_L10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.000364</td>\n",
       "      <td>ivv_w10_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.000364</td>\n",
       "      <td>ivv_w10_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.000285</td>\n",
       "      <td>ivv_w126_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.000285</td>\n",
       "      <td>ivv_w126_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.000262</td>\n",
       "      <td>ivv_w189_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.000262</td>\n",
       "      <td>ivv_w189_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.000224</td>\n",
       "      <td>ivv_w252_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.000224</td>\n",
       "      <td>ivv_w252_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>ivv_w126_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>ivv_w126_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.000179</td>\n",
       "      <td>ivv_rank_v_L126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000179</td>\n",
       "      <td>ivv_rank_p_L126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.000112</td>\n",
       "      <td>ivv_w84_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.000112</td>\n",
       "      <td>ivv_w84_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>ivv_w126_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>ivv_w126_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>ivv_rank_p_L21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>ivv_rank_v_L21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-0.000061</td>\n",
       "      <td>ivv_w5_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-0.000061</td>\n",
       "      <td>ivv_w5_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-0.000080</td>\n",
       "      <td>ivv_w10_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.000080</td>\n",
       "      <td>ivv_w10_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-0.000092</td>\n",
       "      <td>ivv_w84_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.000092</td>\n",
       "      <td>ivv_w84_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.000104</td>\n",
       "      <td>ivv_w189_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.000104</td>\n",
       "      <td>ivv_w189_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.000209</td>\n",
       "      <td>ivv_w84_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-0.000209</td>\n",
       "      <td>ivv_w84_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-0.000244</td>\n",
       "      <td>ivv_w63_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-0.000244</td>\n",
       "      <td>ivv_w63_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-0.000270</td>\n",
       "      <td>ivv_w189_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-0.000270</td>\n",
       "      <td>ivv_w189_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.000273</td>\n",
       "      <td>ivv_w42_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.000273</td>\n",
       "      <td>ivv_w42_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.000303</td>\n",
       "      <td>ivv_w10_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.000303</td>\n",
       "      <td>ivv_w10_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.000329</td>\n",
       "      <td>ivv_rank_v_L05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-0.000329</td>\n",
       "      <td>ivv_rank_p_L05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-0.000350</td>\n",
       "      <td>ivv_rank_v_L63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.000350</td>\n",
       "      <td>ivv_rank_p_L63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-0.000379</td>\n",
       "      <td>ivv_w63_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.000379</td>\n",
       "      <td>ivv_w63_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.000467</td>\n",
       "      <td>ivv_w84_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.000467</td>\n",
       "      <td>ivv_w84_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-0.000477</td>\n",
       "      <td>ivv_w189_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-0.000477</td>\n",
       "      <td>ivv_w189_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-0.000481</td>\n",
       "      <td>ivv_w42_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.000481</td>\n",
       "      <td>ivv_w42_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-0.000508</td>\n",
       "      <td>ivv_w5_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-0.000508</td>\n",
       "      <td>ivv_w5_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-0.000561</td>\n",
       "      <td>ivv_w189_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-0.000561</td>\n",
       "      <td>ivv_w189_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-0.000584</td>\n",
       "      <td>ivv_w126_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-0.000584</td>\n",
       "      <td>ivv_w126_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-0.000648</td>\n",
       "      <td>ivv_w10_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>-0.000648</td>\n",
       "      <td>ivv_w10_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-0.000725</td>\n",
       "      <td>ivv_w126_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-0.000725</td>\n",
       "      <td>ivv_w126_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-0.000769</td>\n",
       "      <td>ivv_w21_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-0.000769</td>\n",
       "      <td>ivv_w21_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-0.000874</td>\n",
       "      <td>ivv_w126_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>-0.000874</td>\n",
       "      <td>ivv_w126_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>-0.000915</td>\n",
       "      <td>ivv_w21_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>-0.000915</td>\n",
       "      <td>ivv_w21_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-0.001018</td>\n",
       "      <td>ivv_w252_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-0.001018</td>\n",
       "      <td>ivv_w252_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-0.001053</td>\n",
       "      <td>ivv_w10_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>-0.001053</td>\n",
       "      <td>ivv_w10_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-0.001055</td>\n",
       "      <td>ivv_rank_p_L42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>-0.001055</td>\n",
       "      <td>ivv_rank_v_L42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-0.001123</td>\n",
       "      <td>ivv_w5_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-0.001123</td>\n",
       "      <td>ivv_w5_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-0.001283</td>\n",
       "      <td>ivv_w63_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-0.001283</td>\n",
       "      <td>ivv_w63_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-0.001298</td>\n",
       "      <td>ivv_w5_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.001298</td>\n",
       "      <td>ivv_w5_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-0.001428</td>\n",
       "      <td>ivv_w5_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-0.001428</td>\n",
       "      <td>ivv_w5_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.001649</td>\n",
       "      <td>ivv_w21_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-0.001649</td>\n",
       "      <td>ivv_w21_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-0.001753</td>\n",
       "      <td>ivv_w21_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-0.001753</td>\n",
       "      <td>ivv_w21_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-0.001760</td>\n",
       "      <td>ivv_w252_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-0.001760</td>\n",
       "      <td>ivv_w252_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.001785</td>\n",
       "      <td>ivv_w42_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.001785</td>\n",
       "      <td>ivv_w42_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-0.001912</td>\n",
       "      <td>ivv_w21_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.001912</td>\n",
       "      <td>ivv_w21_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>-0.002022</td>\n",
       "      <td>ivv_w189_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>-0.002022</td>\n",
       "      <td>ivv_w189_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>-0.002252</td>\n",
       "      <td>ivv_w126_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>-0.002252</td>\n",
       "      <td>ivv_w126_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-0.002367</td>\n",
       "      <td>ivv_w5_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-0.002367</td>\n",
       "      <td>ivv_w5_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-0.002374</td>\n",
       "      <td>ivv_w63_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>-0.002374</td>\n",
       "      <td>ivv_w63_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>-0.002546</td>\n",
       "      <td>ivv_w63_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>-0.002546</td>\n",
       "      <td>ivv_w63_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>-0.002737</td>\n",
       "      <td>ivv_w84_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-0.002737</td>\n",
       "      <td>ivv_w84_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-0.003109</td>\n",
       "      <td>ivv_w84_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-0.003109</td>\n",
       "      <td>ivv_w84_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-0.003256</td>\n",
       "      <td>ivv_w252_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>-0.003256</td>\n",
       "      <td>ivv_w252_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-0.003405</td>\n",
       "      <td>ivv_w63_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-0.003405</td>\n",
       "      <td>ivv_w63_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-0.003449</td>\n",
       "      <td>ivv_w84_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-0.003449</td>\n",
       "      <td>ivv_w84_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>-0.003820</td>\n",
       "      <td>rank_v_L63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>-0.003820</td>\n",
       "      <td>rank_p_L63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-0.004219</td>\n",
       "      <td>w5_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-0.004219</td>\n",
       "      <td>w5_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>-0.004466</td>\n",
       "      <td>w21_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-0.004466</td>\n",
       "      <td>w21_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>-0.004668</td>\n",
       "      <td>ivv_w126_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>-0.004668</td>\n",
       "      <td>ivv_w126_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-0.004757</td>\n",
       "      <td>ivv_w42_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.004757</td>\n",
       "      <td>ivv_w42_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-0.006453</td>\n",
       "      <td>w21_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.006453</td>\n",
       "      <td>w21_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-0.012839</td>\n",
       "      <td>rank_v_L10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-0.012839</td>\n",
       "      <td>rank_p_L10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-0.020091</td>\n",
       "      <td>w5_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>-0.020091</td>\n",
       "      <td>w5_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-0.020701</td>\n",
       "      <td>rank_p_L84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>-0.020701</td>\n",
       "      <td>rank_v_L84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>-0.024708</td>\n",
       "      <td>w5_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-0.024708</td>\n",
       "      <td>w5_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.028150</td>\n",
       "      <td>w5_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-0.028150</td>\n",
       "      <td>w5_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>-0.033936</td>\n",
       "      <td>w10_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.033936</td>\n",
       "      <td>w10_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.045290</td>\n",
       "      <td>rank_p_L21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.045290</td>\n",
       "      <td>rank_v_L21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-0.045294</td>\n",
       "      <td>w126_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.045294</td>\n",
       "      <td>w126_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.046975</td>\n",
       "      <td>w84_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.046975</td>\n",
       "      <td>w84_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.048167</td>\n",
       "      <td>w5_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-0.048167</td>\n",
       "      <td>w5_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.058235</td>\n",
       "      <td>w21_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>-0.058235</td>\n",
       "      <td>w21_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.072005</td>\n",
       "      <td>w10_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-0.072005</td>\n",
       "      <td>w10_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-0.077012</td>\n",
       "      <td>w10_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-0.077012</td>\n",
       "      <td>w10_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>-0.088879</td>\n",
       "      <td>w10_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-0.088879</td>\n",
       "      <td>w10_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>-0.095906</td>\n",
       "      <td>w84_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.095906</td>\n",
       "      <td>w84_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-0.116888</td>\n",
       "      <td>w42_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>-0.116888</td>\n",
       "      <td>w42_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>-0.124061</td>\n",
       "      <td>w63_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.124061</td>\n",
       "      <td>w63_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.124195</td>\n",
       "      <td>w21_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>-0.124195</td>\n",
       "      <td>w21_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>w42_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>w42_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>-0.196093</td>\n",
       "      <td>w42_rank_v_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>-0.196093</td>\n",
       "      <td>w42_rank_p_L05_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-0.203889</td>\n",
       "      <td>w21_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.203889</td>\n",
       "      <td>w21_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.217167</td>\n",
       "      <td>w189_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-0.217167</td>\n",
       "      <td>w189_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-0.254283</td>\n",
       "      <td>w63_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-0.254283</td>\n",
       "      <td>w63_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>-0.260823</td>\n",
       "      <td>w126_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.260823</td>\n",
       "      <td>w126_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.309075</td>\n",
       "      <td>w84_rank_v_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>-0.309075</td>\n",
       "      <td>w84_rank_p_L21_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.333286</td>\n",
       "      <td>w63_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-0.333286</td>\n",
       "      <td>w63_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.393498</td>\n",
       "      <td>w21_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-0.393498</td>\n",
       "      <td>w21_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.415099</td>\n",
       "      <td>w63_rank_v_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-0.415099</td>\n",
       "      <td>w63_rank_p_L189_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.446900</td>\n",
       "      <td>w189_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>-0.446900</td>\n",
       "      <td>w189_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.473768</td>\n",
       "      <td>w252_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.473768</td>\n",
       "      <td>w252_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.474874</td>\n",
       "      <td>w189_rank_v_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.474874</td>\n",
       "      <td>w189_rank_p_L84_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.575155</td>\n",
       "      <td>w63_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-0.575155</td>\n",
       "      <td>w63_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.636291</td>\n",
       "      <td>w189_rank_v_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.636291</td>\n",
       "      <td>w189_rank_p_L42_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.682055</td>\n",
       "      <td>w252_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.682055</td>\n",
       "      <td>w252_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.715560</td>\n",
       "      <td>w252_rank_v_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.715560</td>\n",
       "      <td>w252_rank_p_L63_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.749694</td>\n",
       "      <td>w126_rank_p_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.749694</td>\n",
       "      <td>w126_rank_v_L10_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>-0.831192</td>\n",
       "      <td>w126_rank_v_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>-0.831192</td>\n",
       "      <td>w126_rank_p_L252_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-1.112513</td>\n",
       "      <td>w84_rank_v_L126_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>-1.112513</td>\n",
       "      <td>w84_rank_p_L126_avg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient                   Feature\n",
       "0       0.854918      w252_rank_p_L189_avg\n",
       "1       0.854918      w252_rank_v_L189_avg\n",
       "2       0.700064      w189_rank_p_L252_avg\n",
       "3       0.700064      w189_rank_v_L252_avg\n",
       "4       0.576567       w126_rank_v_L42_avg\n",
       "5       0.576567       w126_rank_p_L42_avg\n",
       "6       0.558991       w189_rank_p_L21_avg\n",
       "7       0.558991       w189_rank_v_L21_avg\n",
       "8       0.529128       w189_rank_p_L05_avg\n",
       "9       0.529128       w189_rank_v_L05_avg\n",
       "10      0.516502      w252_rank_v_L126_avg\n",
       "11      0.516502      w252_rank_p_L126_avg\n",
       "12      0.510651       w126_rank_p_L84_avg\n",
       "13      0.510651       w126_rank_v_L84_avg\n",
       "14      0.443491       w189_rank_p_L63_avg\n",
       "15      0.443491       w189_rank_v_L63_avg\n",
       "16      0.413692       w126_rank_v_L21_avg\n",
       "17      0.413692       w126_rank_p_L21_avg\n",
       "18      0.398268       w63_rank_p_L126_avg\n",
       "19      0.398268       w63_rank_v_L126_avg\n",
       "20      0.374467       w252_rank_p_L21_avg\n",
       "21      0.374467       w252_rank_v_L21_avg\n",
       "22      0.359505        w63_rank_v_L63_avg\n",
       "23      0.359505        w63_rank_p_L63_avg\n",
       "24      0.357035      w189_rank_p_L126_avg\n",
       "25      0.357035      w189_rank_v_L126_avg\n",
       "26      0.337470      w126_rank_v_L126_avg\n",
       "27      0.337470      w126_rank_p_L126_avg\n",
       "28      0.335343        w42_rank_p_L42_avg\n",
       "29      0.335343        w42_rank_v_L42_avg\n",
       "30      0.320384       w42_rank_p_L252_avg\n",
       "31      0.320384       w42_rank_v_L252_avg\n",
       "32      0.313885       w21_rank_p_L252_avg\n",
       "33      0.313885       w21_rank_v_L252_avg\n",
       "34      0.279962       w252_rank_p_L10_avg\n",
       "35      0.279962       w252_rank_v_L10_avg\n",
       "36      0.261484        w84_rank_v_L84_avg\n",
       "37      0.261484        w84_rank_p_L84_avg\n",
       "38      0.257178       w84_rank_p_L252_avg\n",
       "39      0.257178       w84_rank_v_L252_avg\n",
       "40      0.223865       w42_rank_v_L126_avg\n",
       "41      0.223865       w42_rank_p_L126_avg\n",
       "42      0.216226       w252_rank_p_L42_avg\n",
       "43      0.216226       w252_rank_v_L42_avg\n",
       "44      0.196041        w84_rank_v_L05_avg\n",
       "45      0.196041        w84_rank_p_L05_avg\n",
       "46      0.160810       w252_rank_p_L05_avg\n",
       "47      0.160810       w252_rank_v_L05_avg\n",
       "48      0.152409        w84_rank_p_L63_avg\n",
       "49      0.152409        w84_rank_v_L63_avg\n",
       "50      0.151127        w5_rank_v_L126_avg\n",
       "51      0.151127        w5_rank_p_L126_avg\n",
       "52      0.149539        w10_rank_v_L84_avg\n",
       "53      0.149539        w10_rank_p_L84_avg\n",
       "54      0.113896        w63_rank_p_L42_avg\n",
       "55      0.113896        w63_rank_v_L42_avg\n",
       "56      0.105488        w42_rank_p_L10_avg\n",
       "57      0.105488        w42_rank_v_L10_avg\n",
       "58      0.104074       w10_rank_p_L189_avg\n",
       "59      0.104074       w10_rank_v_L189_avg\n",
       "60      0.096456       w84_rank_p_L189_avg\n",
       "61      0.096456       w84_rank_v_L189_avg\n",
       "62      0.079802         w5_rank_p_L63_avg\n",
       "63      0.079802         w5_rank_v_L63_avg\n",
       "64      0.066376        w63_rank_p_L10_avg\n",
       "65      0.066376        w63_rank_v_L10_avg\n",
       "66      0.065465      w126_rank_v_L189_avg\n",
       "67      0.065465      w126_rank_p_L189_avg\n",
       "68      0.050855        w10_rank_p_L21_avg\n",
       "69      0.050855        w10_rank_v_L21_avg\n",
       "70      0.045238        w21_rank_v_L21_avg\n",
       "71      0.045238        w21_rank_p_L21_avg\n",
       "72      0.044993               rank_p_L252\n",
       "73      0.044993               rank_v_L252\n",
       "74      0.042655               rank_v_L126\n",
       "75      0.042655               rank_p_L126\n",
       "76      0.027228       w10_rank_p_L126_avg\n",
       "77      0.027228       w10_rank_v_L126_avg\n",
       "78      0.026194         w5_rank_v_L42_avg\n",
       "79      0.026194         w5_rank_p_L42_avg\n",
       "80      0.023905        w10_rank_p_L10_avg\n",
       "81      0.023905        w10_rank_v_L10_avg\n",
       "82      0.023413        w21_rank_v_L05_avg\n",
       "83      0.023413        w21_rank_p_L05_avg\n",
       "84      0.014465               rank_v_L189\n",
       "85      0.014465               rank_p_L189\n",
       "86      0.009666        w42_rank_p_L21_avg\n",
       "87      0.009666        w42_rank_v_L21_avg\n",
       "88      0.008423       w42_rank_v_L189_avg\n",
       "89      0.008423       w42_rank_p_L189_avg\n",
       "90      0.008272                rank_v_L42\n",
       "91      0.008272                rank_p_L42\n",
       "92      0.005937    ivv_w84_rank_p_L05_avg\n",
       "93      0.005937    ivv_w84_rank_v_L05_avg\n",
       "94      0.004918    ivv_w42_rank_p_L84_avg\n",
       "95      0.004918    ivv_w42_rank_v_L84_avg\n",
       "96      0.004844                rank_v_L05\n",
       "97      0.004844                rank_p_L05\n",
       "98      0.003401   ivv_w189_rank_v_L42_avg\n",
       "99      0.003401   ivv_w189_rank_p_L42_avg\n",
       "100     0.003149    ivv_w21_rank_v_L10_avg\n",
       "101     0.003149    ivv_w21_rank_p_L10_avg\n",
       "102     0.003045    ivv_w42_rank_p_L21_avg\n",
       "103     0.003045    ivv_w42_rank_v_L21_avg\n",
       "104     0.003014    ivv_w21_rank_v_L84_avg\n",
       "105     0.003014    ivv_w21_rank_p_L84_avg\n",
       "106     0.002506    ivv_w10_rank_p_L63_avg\n",
       "107     0.002506    ivv_w10_rank_v_L63_avg\n",
       "108     0.002441   ivv_w189_rank_v_L05_avg\n",
       "109     0.002441   ivv_w189_rank_p_L05_avg\n",
       "110     0.002134         w5_rank_v_L10_avg\n",
       "111     0.002134         w5_rank_p_L10_avg\n",
       "112     0.002066     ivv_w5_rank_v_L42_avg\n",
       "113     0.002066     ivv_w5_rank_p_L42_avg\n",
       "114     0.002059    ivv_w42_rank_v_L63_avg\n",
       "115     0.002059    ivv_w42_rank_p_L63_avg\n",
       "116     0.002009   ivv_w63_rank_p_L252_avg\n",
       "117     0.002009   ivv_w63_rank_v_L252_avg\n",
       "118     0.001821    ivv_w21_rank_p_L63_avg\n",
       "119     0.001821    ivv_w21_rank_v_L63_avg\n",
       "120     0.001819   ivv_w10_rank_p_L126_avg\n",
       "121     0.001819   ivv_w10_rank_v_L126_avg\n",
       "122     0.001720           ivv_rank_p_L252\n",
       "123     0.001720           ivv_rank_v_L252\n",
       "124     0.001720   ivv_w63_rank_v_L189_avg\n",
       "125     0.001720   ivv_w63_rank_p_L189_avg\n",
       "126     0.001705   ivv_w126_rank_v_L42_avg\n",
       "127     0.001705   ivv_w126_rank_p_L42_avg\n",
       "128     0.001698   ivv_w252_rank_v_L10_avg\n",
       "129     0.001698   ivv_w252_rank_p_L10_avg\n",
       "130     0.001624   ivv_w252_rank_p_L42_avg\n",
       "131     0.001624   ivv_w252_rank_v_L42_avg\n",
       "132     0.001456   ivv_w252_rank_v_L63_avg\n",
       "133     0.001456   ivv_w252_rank_p_L63_avg\n",
       "134     0.001414    ivv_w63_rank_p_L05_avg\n",
       "135     0.001414    ivv_w63_rank_v_L05_avg\n",
       "136     0.001334   ivv_w42_rank_v_L126_avg\n",
       "137     0.001334   ivv_w42_rank_p_L126_avg\n",
       "138     0.001208   ivv_w84_rank_v_L252_avg\n",
       "139     0.001208   ivv_w84_rank_p_L252_avg\n",
       "140     0.001153   ivv_w21_rank_v_L189_avg\n",
       "141     0.001153   ivv_w21_rank_p_L189_avg\n",
       "142     0.001037  ivv_w189_rank_p_L126_avg\n",
       "143     0.001037  ivv_w189_rank_v_L126_avg\n",
       "144     0.000996    ivv_w10_rank_p_L05_avg\n",
       "145     0.000996    ivv_w10_rank_v_L05_avg\n",
       "146     0.000979     ivv_w5_rank_v_L05_avg\n",
       "147     0.000979     ivv_w5_rank_p_L05_avg\n",
       "148     0.000696           ivv_rank_v_L189\n",
       "149     0.000696           ivv_rank_p_L189\n",
       "150     0.000622            ivv_rank_v_L84\n",
       "151     0.000622            ivv_rank_p_L84\n",
       "152     0.000620   ivv_w42_rank_v_L189_avg\n",
       "153     0.000620   ivv_w42_rank_p_L189_avg\n",
       "154     0.000586    ivv_w5_rank_p_L189_avg\n",
       "155     0.000586    ivv_w5_rank_v_L189_avg\n",
       "156     0.000532   ivv_w252_rank_p_L21_avg\n",
       "157     0.000532   ivv_w252_rank_v_L21_avg\n",
       "158     0.000529    ivv_w10_rank_p_L21_avg\n",
       "159     0.000529    ivv_w10_rank_v_L21_avg\n",
       "160     0.000476  ivv_w252_rank_v_L189_avg\n",
       "161     0.000476  ivv_w252_rank_p_L189_avg\n",
       "162     0.000429            ivv_rank_v_L10\n",
       "163     0.000429            ivv_rank_p_L10\n",
       "164     0.000364    ivv_w10_rank_v_L10_avg\n",
       "165     0.000364    ivv_w10_rank_p_L10_avg\n",
       "166     0.000285   ivv_w126_rank_v_L10_avg\n",
       "167     0.000285   ivv_w126_rank_p_L10_avg\n",
       "168     0.000262   ivv_w189_rank_v_L63_avg\n",
       "169     0.000262   ivv_w189_rank_p_L63_avg\n",
       "170     0.000224   ivv_w252_rank_p_L84_avg\n",
       "171     0.000224   ivv_w252_rank_v_L84_avg\n",
       "172     0.000201  ivv_w126_rank_v_L126_avg\n",
       "173     0.000201  ivv_w126_rank_p_L126_avg\n",
       "174     0.000179           ivv_rank_v_L126\n",
       "175     0.000179           ivv_rank_p_L126\n",
       "176     0.000112    ivv_w84_rank_v_L84_avg\n",
       "177     0.000112    ivv_w84_rank_p_L84_avg\n",
       "178     0.000107  ivv_w126_rank_v_L189_avg\n",
       "179     0.000107  ivv_w126_rank_p_L189_avg\n",
       "180    -0.000017            ivv_rank_p_L21\n",
       "181    -0.000017            ivv_rank_v_L21\n",
       "182    -0.000061    ivv_w5_rank_v_L252_avg\n",
       "183    -0.000061    ivv_w5_rank_p_L252_avg\n",
       "184    -0.000080    ivv_w10_rank_v_L84_avg\n",
       "185    -0.000080    ivv_w10_rank_p_L84_avg\n",
       "186    -0.000092    ivv_w84_rank_p_L10_avg\n",
       "187    -0.000092    ivv_w84_rank_v_L10_avg\n",
       "188    -0.000104   ivv_w189_rank_v_L10_avg\n",
       "189    -0.000104   ivv_w189_rank_p_L10_avg\n",
       "190    -0.000209    ivv_w84_rank_v_L42_avg\n",
       "191    -0.000209    ivv_w84_rank_p_L42_avg\n",
       "192    -0.000244    ivv_w63_rank_v_L21_avg\n",
       "193    -0.000244    ivv_w63_rank_p_L21_avg\n",
       "194    -0.000270  ivv_w189_rank_v_L252_avg\n",
       "195    -0.000270  ivv_w189_rank_p_L252_avg\n",
       "196    -0.000273    ivv_w42_rank_v_L05_avg\n",
       "197    -0.000273    ivv_w42_rank_p_L05_avg\n",
       "198    -0.000303   ivv_w10_rank_p_L252_avg\n",
       "199    -0.000303   ivv_w10_rank_v_L252_avg\n",
       "200    -0.000329            ivv_rank_v_L05\n",
       "201    -0.000329            ivv_rank_p_L05\n",
       "202    -0.000350            ivv_rank_v_L63\n",
       "203    -0.000350            ivv_rank_p_L63\n",
       "204    -0.000379   ivv_w63_rank_v_L126_avg\n",
       "205    -0.000379   ivv_w63_rank_p_L126_avg\n",
       "206    -0.000467   ivv_w84_rank_v_L189_avg\n",
       "207    -0.000467   ivv_w84_rank_p_L189_avg\n",
       "208    -0.000477   ivv_w189_rank_v_L84_avg\n",
       "209    -0.000477   ivv_w189_rank_p_L84_avg\n",
       "210    -0.000481    ivv_w42_rank_v_L42_avg\n",
       "211    -0.000481    ivv_w42_rank_p_L42_avg\n",
       "212    -0.000508     ivv_w5_rank_p_L21_avg\n",
       "213    -0.000508     ivv_w5_rank_v_L21_avg\n",
       "214    -0.000561   ivv_w189_rank_p_L21_avg\n",
       "215    -0.000561   ivv_w189_rank_v_L21_avg\n",
       "216    -0.000584   ivv_w126_rank_p_L05_avg\n",
       "217    -0.000584   ivv_w126_rank_v_L05_avg\n",
       "218    -0.000648   ivv_w10_rank_v_L189_avg\n",
       "219    -0.000648   ivv_w10_rank_p_L189_avg\n",
       "220    -0.000725   ivv_w126_rank_v_L63_avg\n",
       "221    -0.000725   ivv_w126_rank_p_L63_avg\n",
       "222    -0.000769    ivv_w21_rank_p_L42_avg\n",
       "223    -0.000769    ivv_w21_rank_v_L42_avg\n",
       "224    -0.000874   ivv_w126_rank_p_L84_avg\n",
       "225    -0.000874   ivv_w126_rank_v_L84_avg\n",
       "226    -0.000915   ivv_w21_rank_p_L126_avg\n",
       "227    -0.000915   ivv_w21_rank_v_L126_avg\n",
       "228    -0.001018   ivv_w252_rank_v_L05_avg\n",
       "229    -0.001018   ivv_w252_rank_p_L05_avg\n",
       "230    -0.001053    ivv_w10_rank_p_L42_avg\n",
       "231    -0.001053    ivv_w10_rank_v_L42_avg\n",
       "232    -0.001055            ivv_rank_p_L42\n",
       "233    -0.001055            ivv_rank_v_L42\n",
       "234    -0.001123     ivv_w5_rank_v_L10_avg\n",
       "235    -0.001123     ivv_w5_rank_p_L10_avg\n",
       "236    -0.001283    ivv_w63_rank_v_L63_avg\n",
       "237    -0.001283    ivv_w63_rank_p_L63_avg\n",
       "238    -0.001298    ivv_w5_rank_v_L126_avg\n",
       "239    -0.001298    ivv_w5_rank_p_L126_avg\n",
       "240    -0.001428     ivv_w5_rank_p_L84_avg\n",
       "241    -0.001428     ivv_w5_rank_v_L84_avg\n",
       "242    -0.001649    ivv_w21_rank_p_L21_avg\n",
       "243    -0.001649    ivv_w21_rank_v_L21_avg\n",
       "244    -0.001753    ivv_w21_rank_p_L05_avg\n",
       "245    -0.001753    ivv_w21_rank_v_L05_avg\n",
       "246    -0.001760  ivv_w252_rank_v_L126_avg\n",
       "247    -0.001760  ivv_w252_rank_p_L126_avg\n",
       "248    -0.001785   ivv_w42_rank_p_L252_avg\n",
       "249    -0.001785   ivv_w42_rank_v_L252_avg\n",
       "250    -0.001912   ivv_w21_rank_v_L252_avg\n",
       "251    -0.001912   ivv_w21_rank_p_L252_avg\n",
       "252    -0.002022  ivv_w189_rank_v_L189_avg\n",
       "253    -0.002022  ivv_w189_rank_p_L189_avg\n",
       "254    -0.002252   ivv_w126_rank_v_L21_avg\n",
       "255    -0.002252   ivv_w126_rank_p_L21_avg\n",
       "256    -0.002367     ivv_w5_rank_p_L63_avg\n",
       "257    -0.002367     ivv_w5_rank_v_L63_avg\n",
       "258    -0.002374    ivv_w63_rank_p_L84_avg\n",
       "259    -0.002374    ivv_w63_rank_v_L84_avg\n",
       "260    -0.002546    ivv_w63_rank_v_L10_avg\n",
       "261    -0.002546    ivv_w63_rank_p_L10_avg\n",
       "262    -0.002737   ivv_w84_rank_v_L126_avg\n",
       "263    -0.002737   ivv_w84_rank_p_L126_avg\n",
       "264    -0.003109    ivv_w84_rank_v_L63_avg\n",
       "265    -0.003109    ivv_w84_rank_p_L63_avg\n",
       "266    -0.003256  ivv_w252_rank_v_L252_avg\n",
       "267    -0.003256  ivv_w252_rank_p_L252_avg\n",
       "268    -0.003405    ivv_w63_rank_p_L42_avg\n",
       "269    -0.003405    ivv_w63_rank_v_L42_avg\n",
       "270    -0.003449    ivv_w84_rank_p_L21_avg\n",
       "271    -0.003449    ivv_w84_rank_v_L21_avg\n",
       "272    -0.003820                rank_v_L63\n",
       "273    -0.003820                rank_p_L63\n",
       "274    -0.004219        w5_rank_v_L252_avg\n",
       "275    -0.004219        w5_rank_p_L252_avg\n",
       "276    -0.004466        w21_rank_p_L84_avg\n",
       "277    -0.004466        w21_rank_v_L84_avg\n",
       "278    -0.004668  ivv_w126_rank_p_L252_avg\n",
       "279    -0.004668  ivv_w126_rank_v_L252_avg\n",
       "280    -0.004757    ivv_w42_rank_p_L10_avg\n",
       "281    -0.004757    ivv_w42_rank_v_L10_avg\n",
       "282    -0.006453        w21_rank_p_L10_avg\n",
       "283    -0.006453        w21_rank_v_L10_avg\n",
       "284    -0.012839                rank_v_L10\n",
       "285    -0.012839                rank_p_L10\n",
       "286    -0.020091         w5_rank_p_L05_avg\n",
       "287    -0.020091         w5_rank_v_L05_avg\n",
       "288    -0.020701                rank_p_L84\n",
       "289    -0.020701                rank_v_L84\n",
       "290    -0.024708        w5_rank_p_L189_avg\n",
       "291    -0.024708        w5_rank_v_L189_avg\n",
       "292    -0.028150         w5_rank_p_L84_avg\n",
       "293    -0.028150         w5_rank_v_L84_avg\n",
       "294    -0.033936        w10_rank_p_L05_avg\n",
       "295    -0.033936        w10_rank_v_L05_avg\n",
       "296    -0.045290                rank_p_L21\n",
       "297    -0.045290                rank_v_L21\n",
       "298    -0.045294       w126_rank_v_L05_avg\n",
       "299    -0.045294       w126_rank_p_L05_avg\n",
       "300    -0.046975        w84_rank_p_L10_avg\n",
       "301    -0.046975        w84_rank_v_L10_avg\n",
       "302    -0.048167         w5_rank_v_L21_avg\n",
       "303    -0.048167         w5_rank_p_L21_avg\n",
       "304    -0.058235       w21_rank_v_L189_avg\n",
       "305    -0.058235       w21_rank_p_L189_avg\n",
       "306    -0.072005        w10_rank_v_L63_avg\n",
       "307    -0.072005        w10_rank_p_L63_avg\n",
       "308    -0.077012       w10_rank_p_L252_avg\n",
       "309    -0.077012       w10_rank_v_L252_avg\n",
       "310    -0.088879        w10_rank_v_L42_avg\n",
       "311    -0.088879        w10_rank_p_L42_avg\n",
       "312    -0.095906        w84_rank_p_L42_avg\n",
       "313    -0.095906        w84_rank_v_L42_avg\n",
       "314    -0.116888        w42_rank_p_L84_avg\n",
       "315    -0.116888        w42_rank_v_L84_avg\n",
       "316    -0.124061        w63_rank_v_L05_avg\n",
       "317    -0.124061        w63_rank_p_L05_avg\n",
       "318    -0.124195        w21_rank_p_L42_avg\n",
       "319    -0.124195        w21_rank_v_L42_avg\n",
       "320    -0.142010        w42_rank_p_L63_avg\n",
       "321    -0.142010        w42_rank_v_L63_avg\n",
       "322    -0.196093        w42_rank_v_L05_avg\n",
       "323    -0.196093        w42_rank_p_L05_avg\n",
       "324    -0.203889        w21_rank_p_L63_avg\n",
       "325    -0.203889        w21_rank_v_L63_avg\n",
       "326    -0.217167      w189_rank_v_L189_avg\n",
       "327    -0.217167      w189_rank_p_L189_avg\n",
       "328    -0.254283        w63_rank_v_L21_avg\n",
       "329    -0.254283        w63_rank_p_L21_avg\n",
       "330    -0.260823       w126_rank_v_L63_avg\n",
       "331    -0.260823       w126_rank_p_L63_avg\n",
       "332    -0.309075        w84_rank_v_L21_avg\n",
       "333    -0.309075        w84_rank_p_L21_avg\n",
       "334    -0.333286        w63_rank_v_L84_avg\n",
       "335    -0.333286        w63_rank_p_L84_avg\n",
       "336    -0.393498       w21_rank_v_L126_avg\n",
       "337    -0.393498       w21_rank_p_L126_avg\n",
       "338    -0.415099       w63_rank_v_L189_avg\n",
       "339    -0.415099       w63_rank_p_L189_avg\n",
       "340    -0.446900       w189_rank_p_L10_avg\n",
       "341    -0.446900       w189_rank_v_L10_avg\n",
       "342    -0.473768       w252_rank_p_L84_avg\n",
       "343    -0.473768       w252_rank_v_L84_avg\n",
       "344    -0.474874       w189_rank_v_L84_avg\n",
       "345    -0.474874       w189_rank_p_L84_avg\n",
       "346    -0.575155       w63_rank_p_L252_avg\n",
       "347    -0.575155       w63_rank_v_L252_avg\n",
       "348    -0.636291       w189_rank_v_L42_avg\n",
       "349    -0.636291       w189_rank_p_L42_avg\n",
       "350    -0.682055      w252_rank_v_L252_avg\n",
       "351    -0.682055      w252_rank_p_L252_avg\n",
       "352    -0.715560       w252_rank_v_L63_avg\n",
       "353    -0.715560       w252_rank_p_L63_avg\n",
       "354    -0.749694       w126_rank_p_L10_avg\n",
       "355    -0.749694       w126_rank_v_L10_avg\n",
       "356    -0.831192      w126_rank_v_L252_avg\n",
       "357    -0.831192      w126_rank_p_L252_avg\n",
       "358    -1.112513       w84_rank_v_L126_avg\n",
       "359    -1.112513       w84_rank_p_L126_avg"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coef = pd.DataFrame({'Feature':include_columns,'Coefficient': lm.coef_})\n",
    "model_coef.sort_values(by='Coefficient',inplace=True,ascending=False) \n",
    "model_coef.reset_index(drop=True,inplace=True)\n",
    "model_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"498.88890210493145\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(y_test_nmpy, y_pred_model,marker= 'o', s=50, alpha=0.8)\n",
    "#plt.plot(y_test_nmpy, y_pred_model, 'r-')\n",
    "plt.title('Least-squares linear regression')\n",
    "plt.xlabel('True value (y)')\n",
    "plt.ylabel('Predicted value (y)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
